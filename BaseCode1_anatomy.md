# Import  
## 아는 얼굴들  
pandas, numpy, datetime(얘는 좀 더 만져볼것), math, glod, os, random, datetable?얘는 왜 둘이냐  
seaborn, plt, 
## 처음뵙겠습니다  
re, scipy.interpolate: 이름으로 추측컨대 과학?보다는 데이터 수치해석용 파이썬 툴이고, 다 보간법(맞나) 관련 spline tool이다.
그럼 이산데이터의 중간값 이쁘게 뽑으려고 쓰는거 같다

# seeding  
씨뿌리기를 시전했다! 작성자는 아직 이게 무슨 의미인지 잘 모른 눈치(이)다!  

# loading data  
이거 살짝 신기하다. 그냥 csv나 불러오는줄 알았는데 이걸 찾아가는 함수가 다 있네.  
오늘 나만의 파일 하나 파서 찾아보기 실습해봐야겠다.  
데이터 형태가 형태인만큼 날짜 범위 찍어서 시작 끝, unique 고객 수 이런거 러프하게 따온다  
보다보다 너무 궁금해서 노트북 키고 돌려봤다. pandas 는 데이터.칼럼네임 이렇게 호출 가능하네...익숙해질거 왤케많냐  
몇줄 더 돌려보니까 진짜 아는거랑 해보는거랑 너무 다르다. df. 하위 attribute 궁금해서 검색해보고, 이게 되나? 싶었는데 이게 되네?  
df[df.attribute[1:4]]뭐 이런거... 너무 U stage 에서 신기해야 할거 지금 하는거 같기도 하고...  
  
  
# 1. 어떤 접근?  
시작하자마자 문화컬쳐 충격쇼크. 한글을 변수명으로 받는구나....똘똘한자식...  
pd.date_range 같은애들이 날 낯설게 하는구나. 찾아보니까(써보니까) 그냥 날짜 범위 생성인데,,, 나도 영어랑 안친한건가 아니면 arg 설명이 불친절한건가...  
대충 중간부터 정신을 잃을거 같다. tile형 테이블에 어떤 날짜에, 어떤 유저가 얼만큼을 샀는가... github에서 보던 업로드 타일 그런거 만드는거 같은데 중간논리 빡쎼다. 일단 완성된 8g따리를 만들어봅시다
보니까 맞는거 같다. 모든 24개월간의 길이에 모든 unique 이용자를 매칭해줘 table을 만들고 함수로 합연산..등을 해서 하는거 같은데 내가 dataframe에 익숙하지가 않아서 그른가보다.  
rolling의 경우 이동평균을 써서 분석을 하셨고, 밑에도 product id, description등의 분석을 하셨는데, 전부 논리보다는 다양한, 내가 알지 못하는 모듈의 편의 기능을 사용하신거 같다.  
결론적으로는 전체 데이터를 문제 목적에 맞게 설정 -> 그중에 outlier 색출 -> 유의미한 수치적 의미가 있는지, 제외 가능한지 분석 등의 순서인거 같다.
일반적인 전개가 가장 최우선 되어야 하고, 어떤 요소가 generalization이 별로면 그 요소를 디테일하게 접근? 하는 과정인거 같다. 결국 통계와 논리, 결합/분리의 영역이라 파이썬이랑 더 친해져야 가능할거 같다....  
지금 내가 할만한거는 당장 현실성이 떨어지는 제1, 2안 적인 아이디어를 분해해서 그러한 분석에 활용 가능한 함수 목록을 뽑아보는게 있을거 같다.
