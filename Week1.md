# The truth is  
많은걸 하기로 했는데 별로 못했던거 같다. 아침 7시에 일어나서 산책 돌고 강의 출석시간을 기다리던게 하루만에 쫑나버렸다. 아직도 나는 아침과 싸우는 중이다  
이쯤하고, 뭘 했냐하면은...  
## Compromised on purpose  
타협 아니고 훼손입네다. 너무 철학적인 주제일지 몰라도 내가 수많은 모델들을 손보면서 디폴트로 깔고 가기로 했던 생각은-  
### U don know what you know  
뭐가 중요한지 내가 결정하지 않기로 했다. 수많은 모델들을 사용하는 모든 이유는, 수많은 분류와 카테고리는 내가 다 하기엔 양도 많고 골치아프기 때문이다.  
뭐를 뭐를 기준으로 어떻게 나눌지 전적으로 모델에게 맡겼는데, 내가 복잡한 알고리즘, 법칙을 세워버리면 그건 결국 모델의 일을 내가 하는 거라는 생각이 들었다.  
무튼, 뭐가 중요한지는 위대하신 알파고님이 하시게 두고, 나는 데이터나 batch size같은 환경을 보시기에 심히 좋은 상태로 만들고자 했다.  
강의중에 결측값을 만들고, 채우고, 그리고 어떤 outlier라는 데이터를 어떻게 선정하고, 제거할지 에 대한 이야기도 나왔다. 그래서 떠올렸다. 그냥 아무거나 집으면 안되나?  
### 계획은 있다. 쳐 맞기 전까지는  
그래서 그냥 무작위 결값을 만들면 어떨까 생각했다. KNN 방법으로 나름 data를 손봐주고, smoothing 비슷한 방법을 써보기로 한거다. 운이 좋아 결값이 걸린다면 데이터가 좀 더 거시적인 법칙에 알맞게 바뀔 것이고, 
그것이 아니라면 그냥 그대로 있지 않을까 생각했다. 그래서 비율을 달리해서 NaN값을 생성하고 그걸 KNN 방법으로 메꾸기로 했다.  
#### 첫번쨰 난관과 삽질  
그래서 그냥 돌려봤는데, 주어진 코드는 char를 받지를 못했다. 하긴 그럴법도 한게, a랑 b의 중간값이라는게 어디있겠는가... 그래서 수업시간에 지나가면서 흥미롭게 본 인코딩 라벨링 할까 하다가....  
다행히도 코드 분석 단계에서 feature engineering1 함수가 애초에 그런 역할을 통해서 feature를 뱉어낸다는걸 알고 inference 함수 내에서 결값 생성, 메꾸기를 진행했다. 진짜 알고 할 일인거 같다.  
처음 raw data 결값 만들겠다고 cudf를 만났다. 모델처럼 pd.dataframe을 GPU 가속을 시키고 싶었기 떄문이다. 결값 생성에만 30분정도 걸렸는데 그거 삑나니까 좀 당황했었다. 그러게 env 설정부터 온갖 뻘짓을 다 하다가 feature 엔지니어링에서 결값 생성하니까 5분도 안걸리더라  
요는... 절망적일정도로 정직하게 정답에서 멀어지고 있었다.  
0.1비율로 해서 떨어지고... 0.2 로 하니 더 떨어지고... 0.05로 하니까 거짓말처럼 정답 근처에서 놀았으면 놀았지 더 나아지지는 않았다. 조금 당황했던거 같다. 현재를 보고 미래를 판단할지언정   
미래는 현재에 의해서 결정된다고 생각하지는 않았다. 애초에 마스터님이 진행한 EDA에 있어서도 대부분이 모호한 근거였지 label 1과 0을 결정짓는 판단 근거는 칼같이 정해지는게 아니였다.  
무엇보다 데이터를 훼손시켰다고 해서 그렇게나 정직하게 점수가 떨어진다는 것이...뭔가 원본 데이터가 정답에 대한(적어도 AUC0.8 이하에서는) 굉장히 구체적인 가이드가 되고 있다는 기분마저 들었다.  
## 다른 모델들  
그래서 결국 교훈은 무엇이 중요한지 모른다고 해서 내 마음대로 원본 데이터를 훼손/복구한다고 성능의 향상을 기대 할 수 없다는 것이다. 그래서 그 뒤로는 그냥 하이퍼파라미터를 공부할 수 밖에 없었다.  
LightGBM 사이트에 들어가서, 각 h_P 가 무슨 의미를 가지는지, 설정 가능한 변수는 무엇이 있는지 만지작 대는 정도였다. 그래서 기억에 남는건 random forest인가 GOSS 방식을 통해서 맨날 찍히던 0.75정도의 AUC가 조금 늘었다는 정도이다.  
오피스 아워에서 제공된 자료를 포함해서, Gbm이나 다양한 분류기의 설정과 이론을 얕게나마 알아보고, 내가 생각하는 중요한 변수들을 만져봐야겠다.  


# last thoughts  
그놈의 결측값 생성에 시간이랑 제출횟수도 신나게 써버리는 바람에 다음 제출에는 별거 아니더라도 계획을 좀 짜고 제출할 기준(코드에 뜨는 AUC라던가)을 정하고 어떤 tuning을 적용해서 제출할지 정해야겠다.  
당장 떠오르는 것은 항목 제거이다. 유의미한 무의미한 정보가 나름 뚜렷하게 주어졌다고 생각한다. cumsum_quantity가 제일 인상적이였던걸 기억하면 이걸 포함시키고, 목록 중에서 너무 뻔한건 좀 없애고 해야겠다.  
물론 이것도 잘 못하겠더라.  feature 프로세싱 과정 함수를 완벽하게 까본건 아니라 train과 feature 아웃풋으로 주어지는 features 파이썬 파일을 봐도 내맘대로 편집이 안되더라. 원하는거 넣고, 뺴고, 항목제거를 좀 하고 돌려봐야겠다.  

* 그나마 했던 베이스라인 독후감: <https://github.com/BGCho96/P-stage-2/blob/main/BaseCode1_anatomy.md>
